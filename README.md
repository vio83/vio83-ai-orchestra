<p align="center">
  <img src="https://img.shields.io/badge/VIO_83-AI_ORCHESTRA-00ff00?style=for-the-badge&logo=music&logoColor=black" alt="VIO 83 AI ORCHESTRA" />
</p>

<h1 align="center">ğŸµ VIO 83 AI ORCHESTRA</h1>

<p align="center">
  <strong>The World's First Intelligent Multi-AI Orchestration Platform</strong><br>
  <em>One app. Every AI. Smart routing. Verified answers.</em>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Claude-Opus_4-D97706?style=flat-square&logo=anthropic" />
  <img src="https://img.shields.io/badge/GPT--4o-OpenAI-10B981?style=flat-square&logo=openai" />
  <img src="https://img.shields.io/badge/Grok_2-xAI-3B82F6?style=flat-square" />
  <img src="https://img.shields.io/badge/Mistral-Large-8B5CF6?style=flat-square" />
  <img src="https://img.shields.io/badge/DeepSeek-R1-EC4899?style=flat-square" />
  <img src="https://img.shields.io/badge/Ollama-Local-00ff00?style=flat-square" />
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Tauri_2.0-Rust_+_WebView-FFC131?style=flat-square&logo=tauri" />
  <img src="https://img.shields.io/badge/React_19-TypeScript-61DAFB?style=flat-square&logo=react" />
  <img src="https://img.shields.io/badge/LiteLLM-100+_Providers-FF6B6B?style=flat-square" />
  <img src="https://img.shields.io/badge/License-Proprietary_+_AGPL--3.0-red?style=flat-square" />
</p>

<p align="center">
  <a href="#-why-vio-83">Why VIO 83?</a> â€¢
  <a href="#-features">Features</a> â€¢
  <a href="#-quick-start">Quick Start</a> â€¢
  <a href="#-architecture">Architecture</a> â€¢
  <a href="#-sponsor">Sponsor</a>
</p>

---

## ğŸ¯ Why VIO 83?

**The problem is simple**: today you pay for 5 different AI subscriptions, switch between 10 browser tabs, get inconsistent answers, and have zero verification that the AI isn't hallucinating.

**VIO 83 AI Orchestra** solves this with one elegant principle:

> **One interface. Every AI model in the world. The smartest one answers your question. Verified.**

### What Makes It Different

| Feature | ChatGPT | Claude.ai | VIO 83 |
|---------|---------|-----------|--------|
| Multiple AI models | âŒ GPT only | âŒ Claude only | âœ… **6+ providers** |
| Smart auto-routing | âŒ | âŒ | âœ… **AI picks the best model per task** |
| Cross-check verification | âŒ | âŒ | âœ… **Second AI verifies the first** |
| RAG with certified sources | âŒ | âŒ | âœ… **Academic/library verification** |
| Works 100% offline | âŒ | âŒ | âœ… **Ollama local models** |
| Desktop native app | âŒ Web only | âŒ Web only | âœ… **Tauri 2.0 (2MB app!)** |
| Privacy-first | âŒ Cloud only | âŒ Cloud only | âœ… **Your data stays on your Mac** |
| Source-available | âŒ | âŒ | âœ… **View code, dual-licensed** |

---

## âœ¨ Features

### ğŸ§  Intelligent Routing
The Orchestra doesn't just call an AI â€” it **thinks about which AI to call**:

- **Code questions** â†’ Claude Sonnet (best reasoning) or Qwen Coder (local)
- **Creative writing** â†’ GPT-4o (strongest creative) or Llama (local)
- **Real-time info** â†’ Grok 2 (connected to X/Twitter)
- **Deep reasoning** â†’ Claude Opus or DeepSeek R1
- **Quick tasks** â†’ Haiku or Gemma 2 (fastest, cheapest)

### ğŸ” Cross-Check Verification
For critical answers, a **second AI model** independently verifies the first response. If they disagree, you see both perspectives with a concordance score.

### ğŸ“š RAG â€” Certified Knowledge Base
Every answer can be checked against a local database of **verified sources** â€” academic papers, official documentation, library records. No social media noise. No hallucinations passing as facts.

Quality badges on every response:
- ğŸ¥‡ **Gold** â€” Verified by 3+ certified sources
- ğŸ¥ˆ **Silver** â€” Partially corroborated
- ğŸ¥‰ **Bronze** â€” Low confidence, use with caution
- âšª **Unverified** â€” No matching sources found

### ğŸŒ Cloud + Local: You Choose
- **Cloud Mode**: Always-latest models via API (Claude Opus 4, GPT-4o, Grok 2, Mistral Large, DeepSeek R1)
- **Local Mode**: 100% offline with Ollama (Llama 3.2, Qwen, Mistral, Phi-3, Gemma 2)
- **Hybrid Mode**: Cloud primary, local fallback when offline

### ğŸ”’ Security First
- API keys stored in **macOS Keychain** (hardware-encrypted)
- Local mode = zero data leaves your machine
- No telemetry, no tracking, no data collection
- Open source = fully auditable

### ğŸ¨ Vio Dark Fluorescent Theme
A custom-designed dark theme optimized for long coding sessions:
- Pure black background (#000000)
- Fluorescent green accents (#00FF00)
- Magenta highlights (#FF00FF)
- Cyan cursor (#00FFFF)
- JetBrains Mono for code, Inter for UI

---

## ğŸš€ Quick Start

### Prerequisites
- **macOS** (Apple Silicon recommended)
- **Node.js** 20+ (`nvm install 20`)
- **Rust** (`curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh`)
- **Python** 3.11+ (`brew install python`)
- **Ollama** (`brew install ollama`)

### Install

```bash
# Clone
git clone https://github.com/vio83/vio83-ai-orchestra.git
cd vio83-ai-orchestra

# Frontend
npm install

# Backend
pip3 install litellm fastapi uvicorn chromadb anthropic openai httpx

# Download a local model
ollama pull qwen2.5-coder:3b

# Configure API keys (optional, for cloud mode)
cp .env.example .env
# Edit .env with your keys
```

### Run

```bash
# Terminal 1: Backend API
python -m backend.api.server

# Terminal 2: Frontend dev server
npm run dev

# Terminal 3 (optional): Tauri desktop app
npm run tauri dev
```

Open `http://localhost:5173` â€” your Orchestra is ready. ğŸµ

---

## ğŸ— Architecture

```
USER types a question
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend (React/Tauri)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Request Classifier      â”‚  â† Categorizes: code/creative/analysis/realtime
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  CLOUD MODE?   â”‚
    â”‚                â”‚
    â”‚ YES â†’ LiteLLM  â”‚ â†’ Claude / GPT-4 / Grok / Mistral / DeepSeek
    â”‚                â”‚
    â”‚ NO â†’ Ollama    â”‚ â†’ Llama / Qwen / Mistral / Phi (on your Mac)
    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Cross-Check (optional)  â”‚  â† Second AI validates first response
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RAG Verification        â”‚  â† Check against certified sources
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
   Response + Quality Badge
            â†“
      USER gets verified answer âœ“
```

### Tech Stack

| Layer | Technology | Why |
|-------|-----------|-----|
| Desktop | **Tauri 2.0** | 2MB app vs 100MB Electron. Native performance. |
| Frontend | **React 19 + TypeScript** | World's largest ecosystem. Type-safe. |
| Styling | **Tailwind CSS** | Utility-first, fast to write. |
| State | **Zustand** | 1KB, simple, powerful. |
| AI Gateway | **LiteLLM** | 100+ providers, unified API. Used by Netflix. |
| Local AI | **Ollama** | Run any model locally. Privacy-first. |
| Backend | **FastAPI** | Fastest Python web framework. Async. |
| Vector DB | **ChromaDB** | Embeddings + semantic search for RAG. |
| Security | **macOS Keychain** | Hardware-encrypted key storage. |

---

## ğŸ“Š Supported Models

### Cloud (API required)
| Provider | Model | Best For | Context |
|----------|-------|----------|---------|
| Anthropic | Claude Opus 4 | Complex reasoning, research | 200K |
| Anthropic | Claude Sonnet 4 | Code, analysis, writing | 200K |
| OpenAI | GPT-4o | Creative, multimodal | 128K |
| xAI | Grok 2 | Real-time info, unfiltered | 131K |
| Mistral | Mistral Large | Multilingual, reasoning | 128K |
| DeepSeek | DeepSeek R1 | Math, science, deep reasoning | 64K |

### Local (Ollama, no API needed)
| Model | Size | RAM | Best For |
|-------|------|-----|----------|
| Qwen 2.5 Coder 3B | 2.0 GB | 2.5 GB | Code generation |
| Llama 3.2 3B | 2.0 GB | 2.5 GB | General assistant |
| Mistral 7B | 4.1 GB | 5.0 GB | Reasoning |
| Phi-3 3.8B | 2.3 GB | 3.0 GB | Efficient reasoning |
| DeepSeek Coder V2 Lite | 2.5 GB | 3.5 GB | Code + debugging |
| Gemma 2 2B | 1.6 GB | 2.0 GB | Ultra-fast responses |

---

## ğŸ—º Roadmap

- [x] **Phase 1** â€” Core architecture (Tauri + React + TypeScript)
- [x] **Phase 2** â€” AI orchestrator with smart routing
- [x] **Phase 3** â€” RAG engine with verified sources
- [ ] **Phase 4** â€” VS Code extension
- [ ] **Phase 5** â€” iPhone companion app (iCloud sync)
- [ ] **Phase 6** â€” Marketplace for custom AI workflows
- [ ] **Phase 7** â€” Enterprise features (team management, SSO)

---

## ğŸ’š Sponsor This Project

<p align="center">
  <a href="https://github.com/sponsors/vio83">
    <img src="https://img.shields.io/badge/GitHub_Sponsors-Become_a_Sponsor-ea4aaa?style=for-the-badge&logo=github-sponsors" />
  </a>
  &nbsp;&nbsp;
  <a href="https://ko-fi.com/vio83">
    <img src="https://img.shields.io/badge/Ko--fi-Support_on_Ko--fi-FF5E5B?style=for-the-badge&logo=ko-fi" />
  </a>
  &nbsp;&nbsp;
  <a href="https://www.linkedin.com/in/viorica-porcu-637735139">
    <img src="https://img.shields.io/badge/LinkedIn-Connect-0077B5?style=for-the-badge&logo=linkedin" />
  </a>
</p>

### The Story

I'm **Viorica**, a solo developer from Italy building this on a **MacBook Air M1 with 8GB RAM**. No VC funding. No team. No salary. Just pure determination and 16-hour coding sessions.

I'm building VIO 83 because I believe access to intelligent AI should not require 5 separate subscriptions, and that **verified, trustworthy answers** matter more than fast, unverified ones.

### What Your Sponsorship Funds

| Priority | Need | Why It Matters |
|----------|------|----------------|
| **#1 Critical** | API costs (Claude, GPT-4, Grok) | Testing all providers requires real API credits every day |
| **#2 Hardware** | Mac Studio M4 Ultra (192GB) | Current M1 8GB cannot run large local models â€” limits development severely |
| **#3 Time** | Full-time development | More hours = faster features, better quality |
| **#4 Infrastructure** | Server for the Knowledge Base | 250M+ academic papers need storage and processing power |

### Current Progress (Live)

```
Backend Engine:       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘  85%  (15 modules, all tested)
Knowledge Base:       â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  10%  (10K docs, target 10M+)
Frontend UI:          â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  10%  (Tauri initialized)
API Connectors:       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  30%  (3/11 sources active)
42-Category System:   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  100% (1,082 sub-disciplines)
```

### Sponsor Tiers

| Tier | Monthly | What You Get |
|------|---------|--------------|
| â˜• **Supporter** | $5 | Name in SPONSORS.md + early access to all releases |
| ğŸµ **Musician** | $15 | Above + priority on feature requests + private Discord channel |
| ğŸ¼ **Conductor** | $50 | Above + monthly video call with me + custom AI routing rules for your use case |
| ğŸ† **Patron** | $100 | Above + your logo in the app UI + dedicated support + influence on roadmap |
| ğŸ¢ **Enterprise** | $500 | Commercial license + custom deployment + 1:1 integration support |

### Why Sponsor Now?

This project has **16,255 lines of working code**, **20 commits**, a **real harvesting engine** that has already downloaded **10,000+ academic documents** from Crossref at 122 docs/sec, and a **42-category knowledge classification system** with 1,082 sub-disciplines that doesn't exist anywhere else.

Early sponsors get the best deal: **lifetime perks** at launch-era prices. When VIO 83 ships its first public release, these tiers will increase.

---

## ğŸ“„ License

**Dual Licensed:**

| Use Case | License | What It Means |
|----------|---------|---------------|
| **Commercial** | [Proprietary](LICENSE-PROPRIETARY) | All Rights Reserved. Contact for licensing. |
| **Open Source** | [AGPL-3.0](LICENSE-AGPL-3.0) | Free to use, must share source, network use = distribution |

See [LICENSE](LICENSE) for full details. Copyright (c) 2026 Viorica Porcu (vio83).

The source code is visible for transparency, but **unauthorized copying, modification, or commercial use is prohibited** without explicit written authorization. This project is protected under Italian copyright law (L. 633/1941), EU directives, and international treaties (Berne Convention, WIPO).

---

## ğŸ¤ Contributing

Contributions are welcome under the AGPL-3.0 license. By submitting a PR, you agree to license your contribution under the same dual-license terms.

```bash
git checkout -b feature/your-feature
# Make changes, test thoroughly
git push origin feature/your-feature
# Submit PR with clear description
```

---

<p align="center">
  <strong>Built with determination by Viorica (vio83) â€” Italy</strong><br>
  <em>One developer. One vision. The entire AI world in one app.</em><br>
  <em>Copyright (c) 2026 Viorica Porcu. All Rights Reserved.</em>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Made_in-Italy-008C45?style=flat-square" />
  <img src="https://img.shields.io/badge/Status-Active_Development-00ff00?style=flat-square" />
  <img src="https://img.shields.io/badge/Code-16,255_lines-blue?style=flat-square" />
</p>
